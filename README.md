# Factuality & Bias Review

This repository collects systematic evaluations of factual inconsistencies and bias patterns in large language models (LLMs), across different domains and prompts.

Our goal is to document, compare, and analyze how LLMs handle:
- ✅ Factual accuracy across contexts
- ✅ Implicit and explicit biases
- ✅ Cultural, educational, and geographic assumptions
- ✅ Model-specific hallucinations

## 📁 Structure

Each subfolder focuses on a specific bias or factuality issue:

- `geographic-hallucinations/`: Confusions between places with similar names or incorrect geographic inferences.
- `historical-figures/`: Misrepresentations or bias in biographical prompts.
- `gender-stereotypes/`: Subtle or overt gender-related bias across various contexts.
- `majority-bias/`: Overgeneralization favoring majority cultures, views, or perspectives.

Additional case studies will be added regularly. All examples are documented with prompt → output pairs and brief annotations for reproducibility and future benchmarking.

## 🧪 Coming soon
Evaluation scripts and scoring templates for reproducible benchmarking and cross-model comparisons.

