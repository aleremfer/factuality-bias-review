# Geographic Hallucinations

This folder contains case studies where large language models (LLMs) confuse locations with similar names or make incorrect geographic inferences.

Each case includes:
- âœ… The original prompt
- âŒ The modelâ€™s (incorrect) output
- ğŸ“Œ A brief explanation of the error and potential source of confusion
